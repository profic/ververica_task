//package task.tmp
//
//import java.net.SocketAddress
//
//import com.twitter.finagle.client.{StackClient, StdStackClient, Transporter}
//import com.twitter.finagle.dispatch.{SerialClientDispatcher, SerialServerDispatcher}
//import com.twitter.finagle.netty4.{Netty4Listener, Netty4Transporter}
//import com.twitter.finagle.server.{Listener, StackServer, StdStackServer}
//import com.twitter.finagle.stats.{NullStatsReceiver, StatsReceiver}
//import com.twitter.finagle.transport.{Transport, TransportContext}
//import com.twitter.finagle.{Service, ServiceFactory, Stack}
//import com.twitter.util.{Await, Closable, Future}
//import io.netty.channel.ChannelPipeline
//import io.netty.handler.codec.string.{StringDecoder, StringEncoder}
//import io.netty.util.CharsetUtil
//import task.tmp.Piper.Client
//
//object PiperCLientTest {
//  def main(args: Array[String]): Unit = {
//    val client = new Client().newService(":10042")
//    val r = client("""
//                     | 1) Are the thing stored in the queue always written to disk or is there some kind of "first keep in memory and when there is no more (configurable) space, store to disk"?
//                     | 2) If the second case, does it mean I can configure my queue to always write to disk if desired?
//                     | 3) If I understand well, the memory used is not managed by the JVM itself but by the OS (through the use of memory mapped file)?
//                     | 4) If yes, does it mean if the JVM crash, what was not yet written to disk is not lost? And will be written to disk eventually?
//                     | 5) If yes, If I start the application again, will it be able to resume reading and writing to the same queue without loss of message?
//                     |
//                     |
//                     | 1) By default, Queue writes synchronously to the OS and lets the OS write the data when it can.  You can change this so that it will not return from finish() unless the OS says it has written the data to disk.
//                     |2) Yes.
//                     |3) The memory is managed by the OS so there is nothing for the JVM to do as such.  This memory doesn't use any heap (except a few objects to manage the native memory)
//                     |4) after finish() returns, and the JVM crashes, the data will still be written to disk.  If the JVM crashes in the middle of writing a message, the message is truncated.
//                     | If the OS crashes before data has been written, it can be lost.  If this is a concern you can use replication to mitigate this.
//                     |5) If the OS hasn't died, you will be able to continue reading and writing from where you were up date.
//                     |
//                     |
//                     |
//                     |Chronicle has been tested where the consumer was more than the whole of main memory behind the producer. This reduced the maximum throughput by about half. Most systems,
//                     | in Java, where the queue exceeds the size of main memory, cause the machine to become unusable.
//                     |
//                     |The limit is about 1 GB, as of Chronicle 4.x. The practical limit without tuning the configuration is about 16 MB. At this point you get significant inefficiencies, unless you increase the data allocation chunk size.
//                     |
//                     |
//                     |
//                     |
//                     |
//                     |Chronicle Queue manages storage by cycle. You can add a StoreFileListener which will notify you when a file is added,
//                     | and when it is no longer retained. You can move, compress, or delete all the messages for a day, at once.
//                     | NOTE : Unfortunately on Windows, if an IO operation is interrupted, it can close the underlying FileChannel.
//                     |
//                     |
//                     |
//                     |Файлы будуть продолжать создаваться даже если новые данные не будут поступать
//                     |
//                     |
//                     |
//                     |
//                     |
//                     | Chronicle Queue holds reference to a file until it rolls to new Roll cycle. Deleting current roll cycle's file
//                     | doesn't unmap the file from memory, and that is intended behaviour. If you need to delete files generated by
//                     | Chronicle you need to delete them after they roll. If you need to do that often, consider changing the roll cycle
//                     | to RollCycles.MINUTELY - then you will have new file every minute.
//                     |
//                     |
//                     |
//                     |
//                     |The blockSize determine the basic block size however an overlap between block of 25% is used to make accessed more efficient.
//                     |The default blockSize is 64 MB and so the minimum file size is 80 MB.  On UNIX and MacOSX files are allocated lazily so you only
//                     | the the pages on disk which you touch, this means no matter the blockSize the minimum file space used by default is around 0.5 MB (for the two levels of indexes)
//                     |
//                     |
//                     |
//                     |
//                     |for each appender, messages are written in the order the appender wrote them. Messages by different appenders are interleaved,
//                     |
//                     |for each tailer, it will see every message for a topic in the same order as every other tailer,
//                     |""".stripMargin)
//    val ans = Await.result(r)
//    println(s"ans = ${ans}")
//  }
//}
//
//object Piper extends App {
//
//  type Request = String
//  type Response = String
//
//  class Server extends StdStackServer[Request, Response, Server] {
//
//    override def stack: Stack[ServiceFactory[Request, Response]] = StackServer.newStack[Request, Response]
//
//    override def params: Stack.Params = StackServer.defaultParams
//
//    override type In = Request
//    override type Out = Response
//    override type Context = TransportContext
//
//    private def pipelineInitializer(pipeline: ChannelPipeline): Unit = {
//      pipeline.addLast("in:stringDecoder", new StringDecoder(CharsetUtil.UTF_8))
//      pipeline.addLast("out:stringEncoder", new StringEncoder(CharsetUtil.UTF_8))
//    }
//
//    override protected def newListener(): Listener[In, Out, Context] = {
//      Netty4Listener(pipelineInitializer, params)
//    }
//
//    override protected def newDispatcher(transport: Transport[Request, Response] {type Context <: TransportContext}, service: Service[Request, Response]): Closable = {
//      new SerialServerDispatcher(transport, service)
//    }
//
//    override protected def copy1(newStack: Stack[ServiceFactory[In, Out]], newParams: Stack.Params): Server = {
//      new Server() {
//        override def stack: Stack[ServiceFactory[Request, Response]] = newStack
//
//        override def params: Stack.Params = newParams
//      }
//    }
//  }
//
//  class Client extends StdStackClient[Request, Response, Client] {
//
//    override def stack: Stack[ServiceFactory[Request, Response]] = StackClient.newStack[Request, Response]
//
//    override def params: Stack.Params = StackClient.defaultParams
//
//    override type In = Request
//    override type Out = Response
//    override type Context = TransportContext
//
//    protected val statsReceiver: StatsReceiver = NullStatsReceiver
//
//    private def pipelineInitializer(pipeline: ChannelPipeline): Unit = {
//      pipeline.addLast("in:stringEncoder", new StringEncoder(CharsetUtil.UTF_8))
//      pipeline.addLast("out:stringDecoder", new StringDecoder(CharsetUtil.UTF_8))
//    }
//
//    override protected def newTransporter(addr: SocketAddress): Transporter[In, Out, Context] = {
//      Netty4Transporter.raw[In, Out](pipelineInitializer, addr, params)
//    }
//
//    override protected def newDispatcher(transport: Transport[In, Out] {type Context <: TransportContext}): Service[Request, Response] = {
//      new SerialClientDispatcher(transport, statsReceiver)
//    }
//
//    protected override def copy1(newStack: Stack[ServiceFactory[Request, Response]], newParams: Stack.Params): Client = {
//      new Client() {
//        override def stack: Stack[ServiceFactory[Request, Response]] = newStack
//
//        override def params: Stack.Params = newParams
//      }
//    }
//  }
//
//  def serve(port: Int): Unit = {
//    val server = new Server().serve(s"localhost:$port", new Service[String, String] {
//      override def apply(request: String): Future[String] = Future.value(request)
//    })
//    Await.ready(server)
//    println(s"Serving on $port...")
//  }
//
//  serve(9000)
//}